{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-01T21:01:40.078473Z","iopub.execute_input":"2024-10-01T21:01:40.078846Z","iopub.status.idle":"2024-10-01T21:01:41.143113Z","shell.execute_reply.started":"2024-10-01T21:01:40.078804Z","shell.execute_reply":"2024-10-01T21:01:41.142041Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!ls \n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:01:41.145049Z","iopub.execute_input":"2024-10-01T21:01:41.146166Z","iopub.status.idle":"2024-10-01T21:01:42.277470Z","shell.execute_reply.started":"2024-10-01T21:01:41.146125Z","shell.execute_reply":"2024-10-01T21:01:42.276133Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:01:42.279338Z","iopub.execute_input":"2024-10-01T21:01:42.280099Z","iopub.status.idle":"2024-10-01T21:01:45.687727Z","shell.execute_reply.started":"2024-10-01T21:01:42.280051Z","shell.execute_reply":"2024-10-01T21:01:45.686922Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:01:45.689837Z","iopub.execute_input":"2024-10-01T21:01:45.690362Z","iopub.status.idle":"2024-10-01T21:01:59.105782Z","shell.execute_reply.started":"2024-10-01T21:01:45.690325Z","shell.execute_reply":"2024-10-01T21:01:59.104533Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting huggingface\n  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\nDownloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\nInstalling collected packages: huggingface\nSuccessfully installed huggingface-0.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\ntoken = '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'\nlogin(token)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:01:59.107415Z","iopub.execute_input":"2024-10-01T21:01:59.107785Z","iopub.status.idle":"2024-10-01T21:01:59.655366Z","shell.execute_reply.started":"2024-10-01T21:01:59.107748Z","shell.execute_reply":"2024-10-01T21:01:59.654435Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:01:59.656515Z","iopub.execute_input":"2024-10-01T21:01:59.656847Z","iopub.status.idle":"2024-10-01T21:01:59.722889Z","shell.execute_reply.started":"2024-10-01T21:01:59.656814Z","shell.execute_reply":"2024-10-01T21:01:59.721806Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:01:59.724423Z","iopub.execute_input":"2024-10-01T21:01:59.724860Z","iopub.status.idle":"2024-10-01T21:02:00.866518Z","shell.execute_reply.started":"2024-10-01T21:01:59.724814Z","shell.execute_reply":"2024-10-01T21:02:00.865371Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Tue Oct  1 21:02:00 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   42C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   41C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q datasets\n!pip install -q -U bitsandbytes\n!pip install -q -U transformers\n!pip install -q -U peft\n!pip install -q -U accelerate\n!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:02:00.868031Z","iopub.execute_input":"2024-10-01T21:02:00.868387Z","iopub.status.idle":"2024-10-01T21:03:32.458594Z","shell.execute_reply.started":"2024-10-01T21:02:00.868351Z","shell.execute_reply":"2024-10-01T21:03:32.457562Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator\naccelerator = Accelerator()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:32.460177Z","iopub.execute_input":"2024-10-01T21:03:32.460511Z","iopub.status.idle":"2024-10-01T21:03:32.873353Z","shell.execute_reply.started":"2024-10-01T21:03:32.460470Z","shell.execute_reply":"2024-10-01T21:03:32.872516Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nimport tqdm\n\nds = load_dataset(\"0xayman/single-function-calls-dataset-28K\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:32.877016Z","iopub.execute_input":"2024-10-01T21:03:32.877692Z","iopub.status.idle":"2024-10-01T21:03:35.411552Z","shell.execute_reply.started":"2024-10-01T21:03:32.877655Z","shell.execute_reply":"2024-10-01T21:03:35.410484Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/402 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f051ae3a5adf41b4af36fa3587625906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/13.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b457bb1b61784cf59e774f85bfaee5cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/28461 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86b8859661c3473c97e3481117d45167"}},"metadata":{}}]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:35.413398Z","iopub.execute_input":"2024-10-01T21:03:35.414010Z","iopub.status.idle":"2024-10-01T21:03:35.420975Z","shell.execute_reply.started":"2024-10-01T21:03:35.413936Z","shell.execute_reply":"2024-10-01T21:03:35.419939Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'query', 'answers', 'tools'],\n        num_rows: 28461\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:35.422464Z","iopub.execute_input":"2024-10-01T21:03:35.423436Z","iopub.status.idle":"2024-10-01T21:03:35.434355Z","shell.execute_reply.started":"2024-10-01T21:03:35.423354Z","shell.execute_reply":"2024-10-01T21:03:35.433408Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'id': 1,\n 'query': \"I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for 'ethereum'?\",\n 'answers': '[{\"name\": \"web_chain_details\", \"arguments\": {\"chain_slug\": \"ethereum\"}}]',\n 'tools': '[{\"name\": \"peers\", \"description\": \"Retrieves a list of company peers given a stock symbol.\", \"parameters\": {\"symbol\": {\"description\": \"The stock symbol for the company.\", \"type\": \"str\", \"default\": \"\"}}}, {\"name\": \"web_chain_details\", \"description\": \"python\", \"parameters\": {\"chain_slug\": {\"description\": \"The slug identifier for the blockchain (e.g., \\'ethereum\\' for Ethereum mainnet).\", \"type\": \"str\", \"default\": \"ethereum\"}}}]'}"},"metadata":{}}]},{"cell_type":"code","source":"import datasets\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:35.435602Z","iopub.execute_input":"2024-10-01T21:03:35.436028Z","iopub.status.idle":"2024-10-01T21:03:35.443156Z","shell.execute_reply.started":"2024-10-01T21:03:35.435934Z","shell.execute_reply":"2024-10-01T21:03:35.441998Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def formatting(sample):\n    query = sample['query']\n    answers = sample['answers']\n    tools = sample['tools']\n    answers = json.loads(answers)\n    assert len(answers) == 1, f\"Each query can only be answered by one function, given {answers}\"\n    answer = answers[0]\n    prompt = f\"\"\"Your task is to select one of the provided functions to answer the user question.\n    You should select the most relevant function and extract its arguments from the user's question.\n    If the user's question doesn't require tool use, answer it from your knowledge. \\n\n    You can select from the following available tools:\\n\n    {tools} \\n\n    You should strictly follow the following tools: \\n\n    1. Your output should ALWAYS be a valid JSON object.\\n\n    2. Do not make up information.\\n\n    3. You cannot use functions that are not provided for you.\\n\n    4. You should pick up only one function to answer the user question.\\n\n    \n    Your output json object should have the followig fields:\\n\n    1. name: the name of the selected function.\\n\n    2. arguments: an object containing all the function's arguments. the arguments object should contains key-value pairs where is key is the name of the argument and the value is the argument's value extracted from the user query.\\n\n    \n    Begin!\\n\n    \n    Question: {query} \\n\n    Answer: {answer}\n    \"\"\"\n    return {'text' : prompt}\n\nds_formatted = ds.map(formatting)\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:35.444678Z","iopub.execute_input":"2024-10-01T21:03:35.445438Z","iopub.status.idle":"2024-10-01T21:03:38.932899Z","shell.execute_reply.started":"2024-10-01T21:03:35.445387Z","shell.execute_reply":"2024-10-01T21:03:38.931880Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28461 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d6511f1bfe54bfb9b3713a29bc9d13f"}},"metadata":{}}]},{"cell_type":"code","source":"ds_formatted = ds_formatted['train'].train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:38.934151Z","iopub.execute_input":"2024-10-01T21:03:38.934457Z","iopub.status.idle":"2024-10-01T21:03:38.971328Z","shell.execute_reply.started":"2024-10-01T21:03:38.934424Z","shell.execute_reply":"2024-10-01T21:03:38.970386Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import LlamaForCausalLM, AutoTokenizer, AutoModelForCausalLM\n#from llama_recipes.configs import train_config as TRAIN_CONFIG","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:38.972468Z","iopub.execute_input":"2024-10-01T21:03:38.972777Z","iopub.status.idle":"2024-10-01T21:03:40.151273Z","shell.execute_reply.started":"2024-10-01T21:03:38.972743Z","shell.execute_reply":"2024-10-01T21:03:40.150305Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5993912bef4aaaacb46dab43749b03"}},"metadata":{}}]},{"cell_type":"markdown","source":"Importing the model and setting the training hyperparameters and the quantization configurations.\nUsing QLoRA quantization method, the model is loeaded in Normalized float 4 bit (NF4) and the computations are done in BF16.","metadata":{}},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nconfig = BitsAndBytesConfig(\nload_in_4bit = True,\nbnb_4bit_quant_type = 'nf4',\nbnb_4bit_use_double_quant = True,\nbnb_4bit_compute_dtype = torch.bfloat16)\nmodel_name = \"microsoft/Phi-3.5-mini-instruct\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    quantization_config=config,\n    trust_remote_code = True\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:03:40.152705Z","iopub.execute_input":"2024-10-01T21:03:40.153497Z","iopub.status.idle":"2024-10-01T21:05:11.396816Z","shell.execute_reply.started":"2024-10-01T21:03:40.153447Z","shell.execute_reply":"2024-10-01T21:05:11.395839Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8edc096cc1f469a96a1237f52a0a35f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b299d61eed7467e8763db7fe7e8686a"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e714febdc954e2481371237be688e64"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8982b12cfe47ab923673a215810d71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec514cbf318343648a1d0a5187f0b26f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc0351528e34c98b720cd48c765377b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc4f61fc2564612853f2c9c5241f0ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32cc539f1734454cac2497dd3dc3f53a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162513fcf21142f5a28d663f166b11eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36f8deb8a02e4cf681750d6f8db83b52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7be9edc617a408d94ee54887556dcab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe03dcdde0e484b87839848f26a02d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f96e1fef45454486051307d465bbe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f066c31ed740ec8da357b9d94a46af"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:05:11.397894Z","iopub.execute_input":"2024-10-01T21:05:11.398215Z","iopub.status.idle":"2024-10-01T21:05:11.407261Z","shell.execute_reply.started":"2024-10-01T21:05:11.398183Z","shell.execute_reply":"2024-10-01T21:05:11.406227Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig\nQlora_config = LoraConfig(r = 64,\n                        target_modules = 'all-linear',\n                        lora_alpha = 128,\n                        lora_dropout = 0.05,\n                        task_type = 'CAUSAL_LM')\nmodel = get_peft_model(model, Qlora_config)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:05:11.408288Z","iopub.execute_input":"2024-10-01T21:05:11.408611Z","iopub.status.idle":"2024-10-01T21:05:12.658523Z","shell.execute_reply.started":"2024-10-01T21:05:11.408578Z","shell.execute_reply":"2024-10-01T21:05:12.657492Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"!pip install trl\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:05:12.659775Z","iopub.execute_input":"2024-10-01T21:05:12.660195Z","iopub.status.idle":"2024-10-01T21:05:26.065760Z","shell.execute_reply.started":"2024-10-01T21:05:12.660150Z","shell.execute_reply":"2024-10-01T21:05:26.064563Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.4.0)\nRequirement already satisfied: transformers>=4.40.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.45.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.34.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (3.0.0)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.25.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.40.0->trl) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.11.1 tyro-0.8.11\n","output_type":"stream"}]},{"cell_type":"code","source":"from trl import SFTConfig, SFTTrainer\nfrom transformers import TrainingArguments\nargs = TrainingArguments(per_device_train_batch_size=1,\n                        eval_strategy = 'steps',\n                         eval_steps = 1000,\n                        gradient_accumulation_steps = 4,\n                        learning_rate = 3e-4,\n                        max_steps = 3500,\n                        warmup_steps = 100,\n                        fp16 = True,\n                        output_dir='outputs',\n                        optim=\"paged_adamw_8bit\")\ntrainer = SFTTrainer(\n    model = model,\n    train_dataset = ds_formatted['train'],\n    eval_dataset = ds_formatted['test'],\n    tokenizer = tokenizer,\n    peft_config = Qlora_config,\n    max_seq_length = 1024,\n    dataset_text_field = 'text',\n    args = args\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:05:26.067503Z","iopub.execute_input":"2024-10-01T21:05:26.067884Z","iopub.status.idle":"2024-10-01T21:06:06.238238Z","shell.execute_reply.started":"2024-10-01T21:05:26.067845Z","shell.execute_reply":"2024-10-01T21:06:06.237385Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25614 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764d7b009e59439499f59b78e6965294"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2847 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07bc654911604dd8a6a5c91b207f6e62"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:06:06.239379Z","iopub.execute_input":"2024-10-01T21:06:06.239693Z","iopub.status.idle":"2024-10-02T03:32:03.716206Z","shell.execute_reply.started":"2024-10-01T21:06:06.239657Z","shell.execute_reply":"2024-10-02T03:32:03.715297Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241001_210616-fge0e4lt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface/runs/fge0e4lt' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface' target=\"_blank\">https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface/runs/fge0e4lt' target=\"_blank\">https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface/runs/fge0e4lt</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3500' max='3500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3500/3500 6:25:40, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.219100</td>\n      <td>0.223577</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.133800</td>\n      <td>0.132951</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.091000</td>\n      <td>0.101587</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3500, training_loss=0.16452274540492468, metrics={'train_runtime': 23155.8563, 'train_samples_per_second': 0.605, 'train_steps_per_second': 0.151, 'total_flos': 2.0732657373563904e+17, 'train_loss': 0.16452274540492468, 'epoch': 0.546576091200125})"},"metadata":{}}]},{"cell_type":"code","source":"model_to_save = 'Tasneem10/phi3.5-mini-instruct-fc'\nmodel.push_to_hub(model_to_save)\ntokenizer.push_to_hub(model_to_save)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T03:32:03.717553Z","iopub.execute_input":"2024-10-02T03:32:03.717874Z","iopub.status.idle":"2024-10-02T03:32:21.966885Z","shell.execute_reply.started":"2024-10-02T03:32:03.717838Z","shell.execute_reply":"2024-10-02T03:32:21.966005Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/403M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df0a9bea4d94dd0b4b1fd5b44d0d257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daaf56c896134a32bacbc76d21144790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d6a1796ec2344319cdcbaa0ad0979aa"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Tasneem10/phi3.5-mini-instruct-fc/commit/61864da469a8b3d00ed7c42acf676980fe4fd1b2', commit_message='Upload tokenizer', commit_description='', oid='61864da469a8b3d00ed7c42acf676980fe4fd1b2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Tasneem10/phi3.5-mini-instruct-fc', endpoint='https://huggingface.co', repo_type='model', repo_id='Tasneem10/phi3.5-mini-instruct-fc'), pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}