{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMBCmfxzNNwnAuxgs0EjFj3","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8f2978e744a74312abd89596137c3f59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3919569501474b5a873cc2c515ec127f","IPY_MODEL_14d7e3a710e7456d9110920ac177fe35","IPY_MODEL_569fae6c91e246beac7906e05f99ea33"],"layout":"IPY_MODEL_7c4471ce04f04aa3b0a8a9cf64660c06"}},"3919569501474b5a873cc2c515ec127f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad0a7db7b5c14add8d53e42dbbf345b6","placeholder":"​","style":"IPY_MODEL_3452e66c62134f29b8a15d2727f1e1a6","value":"README.md: 100%"}},"14d7e3a710e7456d9110920ac177fe35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a357ef28d874d58b6937bdfa02d7e63","max":677,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f3d311f60d54f129165e5f6b32d64ac","value":677}},"569fae6c91e246beac7906e05f99ea33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_259ae02af4124b0f9f7d54ad3a732790","placeholder":"​","style":"IPY_MODEL_76e4364104e94891ac5d2770e7ead01d","value":" 677/677 [00:00&lt;00:00, 51.2kB/s]"}},"7c4471ce04f04aa3b0a8a9cf64660c06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad0a7db7b5c14add8d53e42dbbf345b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3452e66c62134f29b8a15d2727f1e1a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a357ef28d874d58b6937bdfa02d7e63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f3d311f60d54f129165e5f6b32d64ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"259ae02af4124b0f9f7d54ad3a732790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76e4364104e94891ac5d2770e7ead01d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d40a32827afa4794b8d14dd5f2695a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0266aa27c6bb4828affcff394096a5bb","IPY_MODEL_ae801c10ecf14165ac212d8a6cdbd8bb","IPY_MODEL_b9fc6220b0f44992a31bfd8d53f4166f"],"layout":"IPY_MODEL_c44918eaa08a4efe8528e706d6cd312d"}},"0266aa27c6bb4828affcff394096a5bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f66cd3e309243b7b88c2cdbc19e4cb1","placeholder":"​","style":"IPY_MODEL_8bdea4291c6749eebe43577197ca0005","value":"(…)-00000-of-00001-e270777bb989ac86.parquet: 100%"}},"ae801c10ecf14165ac212d8a6cdbd8bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08905e706487410f857b1fc3066cf799","max":3450938,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c1348310fe04d25aaa155f9431d4f83","value":3450938}},"b9fc6220b0f44992a31bfd8d53f4166f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a76a7de76644a5cbfc025e597510dfd","placeholder":"​","style":"IPY_MODEL_9e9fa4ab9da140228e01a370218e0f1e","value":" 3.45M/3.45M [00:00&lt;00:00, 29.0MB/s]"}},"c44918eaa08a4efe8528e706d6cd312d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f66cd3e309243b7b88c2cdbc19e4cb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bdea4291c6749eebe43577197ca0005":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08905e706487410f857b1fc3066cf799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c1348310fe04d25aaa155f9431d4f83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a76a7de76644a5cbfc025e597510dfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e9fa4ab9da140228e01a370218e0f1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"519e1aac9aea4e3e96395cd95be866ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9665c24fcc2c4b3c95973d4706a7336e","IPY_MODEL_e5b836a2501c4fbfb2500523f80a543b","IPY_MODEL_eb6d0b9b63424e89969a9070ac7acabf"],"layout":"IPY_MODEL_b8e9af625e8242f2ae2ad31aa78107fe"}},"9665c24fcc2c4b3c95973d4706a7336e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dad3d199ad34c42932f062b2c70ccb3","placeholder":"​","style":"IPY_MODEL_6fce7232a4e3405cac46379a4c93c9d8","value":"Generating train split: 100%"}},"e5b836a2501c4fbfb2500523f80a543b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d32c31a8d794bbfba66332b0fd5058c","max":20022,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e0b990185754b00bda6609fd646187e","value":20022}},"eb6d0b9b63424e89969a9070ac7acabf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13b7e621554d4f7f920a9b7027c7261f","placeholder":"​","style":"IPY_MODEL_7c5676815d304ae497ff941b5b4a4420","value":" 20022/20022 [00:00&lt;00:00, 138898.11 examples/s]"}},"b8e9af625e8242f2ae2ad31aa78107fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dad3d199ad34c42932f062b2c70ccb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fce7232a4e3405cac46379a4c93c9d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d32c31a8d794bbfba66332b0fd5058c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e0b990185754b00bda6609fd646187e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13b7e621554d4f7f920a9b7027c7261f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c5676815d304ae497ff941b5b4a4420":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c46787f455a8489b96ed0bb26f1745d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8d6d8c6dcf24674a57282316efcea8c","IPY_MODEL_2ea50c198743450dbdbf0de20792ffdc","IPY_MODEL_c09d25c0fe3a47da89069a3ee6db3ba3"],"layout":"IPY_MODEL_8f8fabdd7dab415aaf3d827aa6f4a52a"}},"b8d6d8c6dcf24674a57282316efcea8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49aff29f28fe49149731797ed7d98b39","placeholder":"​","style":"IPY_MODEL_feaa05415e624277bdf469b7bbfbfc7b","value":"config.json: 100%"}},"2ea50c198743450dbdbf0de20792ffdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f895f57b2b504f14a5cfbe9892f793f3","max":644,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4385ec5d5a2e443187f3a24eb5411aa7","value":644}},"c09d25c0fe3a47da89069a3ee6db3ba3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76bb07dfe20647b4ae09c29ec66fc582","placeholder":"​","style":"IPY_MODEL_2e6b1697f941404e9ae1aed12f74978d","value":" 644/644 [00:00&lt;00:00, 5.99kB/s]"}},"8f8fabdd7dab415aaf3d827aa6f4a52a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49aff29f28fe49149731797ed7d98b39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feaa05415e624277bdf469b7bbfbfc7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f895f57b2b504f14a5cfbe9892f793f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4385ec5d5a2e443187f3a24eb5411aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76bb07dfe20647b4ae09c29ec66fc582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6b1697f941404e9ae1aed12f74978d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58e0fbbc19b349e2b88f0b6b3e350b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76fbd1c26e1f469a99fa75ee3cd4b62a","IPY_MODEL_da48f9ad47f04e8682c6894d64de258f","IPY_MODEL_d9798f727e8545f2b4a1687ebc2adf7d"],"layout":"IPY_MODEL_225a407f37c64312b2c7a29c5272bd00"}},"76fbd1c26e1f469a99fa75ee3cd4b62a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_988cc653256047d6907d8a4937d9b2d6","placeholder":"​","style":"IPY_MODEL_0e2a8d34ebf64ae680905c16cb44970e","value":"pytorch_model.bin: 100%"}},"da48f9ad47f04e8682c6894d64de258f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d57bcfcb54da4192a25d872872249d51","max":662513657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30a2c4a0a91a459cbb7c53e4ca4066e6","value":662513657}},"d9798f727e8545f2b4a1687ebc2adf7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4b08d7f866f459c89abdb423b412b92","placeholder":"​","style":"IPY_MODEL_e250d9e30c0a4f60bcac44ab1593bdf0","value":" 663M/663M [00:04&lt;00:00, 209MB/s]"}},"225a407f37c64312b2c7a29c5272bd00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"988cc653256047d6907d8a4937d9b2d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e2a8d34ebf64ae680905c16cb44970e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d57bcfcb54da4192a25d872872249d51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30a2c4a0a91a459cbb7c53e4ca4066e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4b08d7f866f459c89abdb423b412b92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e250d9e30c0a4f60bcac44ab1593bdf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"259695c832f0472fa681f789f1dc6bc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9b1dd8ec5fc468db3ecedb2794664c0","IPY_MODEL_680f9129ba104b1aa83efb88f0423872","IPY_MODEL_e7320be8c9a34f97903af775eaeb2f04"],"layout":"IPY_MODEL_dbc40a89999a4a71a32a313263db60d9"}},"e9b1dd8ec5fc468db3ecedb2794664c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae0be095c4b8416e8416c78d8f15cfe3","placeholder":"​","style":"IPY_MODEL_9a2739b091a745ea9a272354b40ac197","value":"generation_config.json: 100%"}},"680f9129ba104b1aa83efb88f0423872":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc596ed1f94341c98acebc03edbb693b","max":137,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c33550e3e1a426c9f1a95a2093bf1f0","value":137}},"e7320be8c9a34f97903af775eaeb2f04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97f410d422134debaceea79f2d9afd29","placeholder":"​","style":"IPY_MODEL_df39e75d6fd24ad899b4bd4ab8bb46be","value":" 137/137 [00:00&lt;00:00, 3.73kB/s]"}},"dbc40a89999a4a71a32a313263db60d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0be095c4b8416e8416c78d8f15cfe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a2739b091a745ea9a272354b40ac197":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc596ed1f94341c98acebc03edbb693b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c33550e3e1a426c9f1a95a2093bf1f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97f410d422134debaceea79f2d9afd29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df39e75d6fd24ad899b4bd4ab8bb46be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5aba7dafd1e4ab181448bc575e57e6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86419dfb4deb4c04954b25d19b80eaf0","IPY_MODEL_31bbd05536bc496cb633675b3950fb25","IPY_MODEL_aaebabc6cc2048629d56def1c25b93b4"],"layout":"IPY_MODEL_0908cfb356ef4677955169a628fb02e0"}},"86419dfb4deb4c04954b25d19b80eaf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_608b7c2d5ad54ce0985b124f9b854813","placeholder":"​","style":"IPY_MODEL_fab3ef52a4524513b6693704cb1f08a3","value":"tokenizer_config.json: 100%"}},"31bbd05536bc496cb633675b3950fb25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a044034175a04cc1b18abb6d86c8c4ce","max":685,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4244ec12616e42458f6a0550dcab43c3","value":685}},"aaebabc6cc2048629d56def1c25b93b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a2657faf29c4932b9fdb570a7e06fde","placeholder":"​","style":"IPY_MODEL_c900c6a43ccd459ebfc1d4faf2ecc059","value":" 685/685 [00:00&lt;00:00, 19.0kB/s]"}},"0908cfb356ef4677955169a628fb02e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"608b7c2d5ad54ce0985b124f9b854813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fab3ef52a4524513b6693704cb1f08a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a044034175a04cc1b18abb6d86c8c4ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4244ec12616e42458f6a0550dcab43c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a2657faf29c4932b9fdb570a7e06fde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c900c6a43ccd459ebfc1d4faf2ecc059":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"773d72791cd54f63a82e860c24166fee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6ca80200c4042d9ac1064aa5cbfd88d","IPY_MODEL_e802041cd4ff4430b22dd94f3d163bd5","IPY_MODEL_abe155e004a44d85a811dc32b9c74732"],"layout":"IPY_MODEL_42e5d3174b3e465c8000df37754891e0"}},"c6ca80200c4042d9ac1064aa5cbfd88d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d7cde81a5d545c4be7afbdee78eaeda","placeholder":"​","style":"IPY_MODEL_2b324a1961584013a1dcc67dfbab1497","value":"vocab.json: 100%"}},"e802041cd4ff4430b22dd94f3d163bd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20fdfd4d7d8b4810864294c0cc59d148","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6b06b3f39424c72906b08a951818483","value":898822}},"abe155e004a44d85a811dc32b9c74732":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb1aa7f8ad9c4998a366c464d2f7fdcf","placeholder":"​","style":"IPY_MODEL_c6ae4687fd1249819d6139c3770d85f6","value":" 899k/899k [00:00&lt;00:00, 1.06MB/s]"}},"42e5d3174b3e465c8000df37754891e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d7cde81a5d545c4be7afbdee78eaeda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b324a1961584013a1dcc67dfbab1497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20fdfd4d7d8b4810864294c0cc59d148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6b06b3f39424c72906b08a951818483":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb1aa7f8ad9c4998a366c464d2f7fdcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ae4687fd1249819d6139c3770d85f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"837bd70524984411b5bb7b7b18e10f79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_083f763458904989ba73a80105ea0d3c","IPY_MODEL_aa6ffdb18de44652954f1e5f1011a0de","IPY_MODEL_43c241ca3b374fd0a49714b52a719a3f"],"layout":"IPY_MODEL_6e617ebfa7e746959731b416d36f8833"}},"083f763458904989ba73a80105ea0d3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aa960b4f50b4b1da5df97ced92a9d01","placeholder":"​","style":"IPY_MODEL_af30a2a979554cce82a71dbde0646c06","value":"merges.txt: 100%"}},"aa6ffdb18de44652954f1e5f1011a0de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_113d30781fbd44e989631c4e44b8776e","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b6980059f3048a7babbc0ac84ec7bf4","value":456318}},"43c241ca3b374fd0a49714b52a719a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6864e46634f4267b3911c059ba79a7a","placeholder":"​","style":"IPY_MODEL_cdb392827c0048b8bcd7ae5f6df7bbcb","value":" 456k/456k [00:00&lt;00:00, 712kB/s]"}},"6e617ebfa7e746959731b416d36f8833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa960b4f50b4b1da5df97ced92a9d01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af30a2a979554cce82a71dbde0646c06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"113d30781fbd44e989631c4e44b8776e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b6980059f3048a7babbc0ac84ec7bf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6864e46634f4267b3911c059ba79a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdb392827c0048b8bcd7ae5f6df7bbcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed4b0d63eddb432dbdd53fb027dc1581":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e002c9a151a4e83928385a9e745a1ea","IPY_MODEL_6eb904c6c636498baa286449e93a6578","IPY_MODEL_936f541ab3f848f48588907d515687bf"],"layout":"IPY_MODEL_1ea3f7e504a0449f90db54c65f0ee690"}},"7e002c9a151a4e83928385a9e745a1ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84c33f9e408445d2bb6f6749c33b53cc","placeholder":"​","style":"IPY_MODEL_de93c542ada94f419e32e4ef09180e7b","value":"special_tokens_map.json: 100%"}},"6eb904c6c636498baa286449e93a6578":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_010c8c1740074280be4f98c8380e234b","max":441,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38e11017c53940079661ef3426dd718a","value":441}},"936f541ab3f848f48588907d515687bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1d5836aac64d3dac733bbda55810e4","placeholder":"​","style":"IPY_MODEL_9a4c79674144493b86bc0ab1a1c742ea","value":" 441/441 [00:00&lt;00:00, 9.95kB/s]"}},"1ea3f7e504a0449f90db54c65f0ee690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c33f9e408445d2bb6f6749c33b53cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de93c542ada94f419e32e4ef09180e7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"010c8c1740074280be4f98c8380e234b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38e11017c53940079661ef3426dd718a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b1d5836aac64d3dac733bbda55810e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a4c79674144493b86bc0ab1a1c742ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e24f25fbf2f24b37b63d6f9b9d891ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ab4eef1d114405b81e44e11d4086d61","IPY_MODEL_c25b1f5cecec42c8ac53f1bb8c9fad82","IPY_MODEL_05f0f47ad6564d58bb9d05b1e84c8857"],"layout":"IPY_MODEL_7ab93e822e3947f0b5c714b5ec689db5"}},"5ab4eef1d114405b81e44e11d4086d61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_435cbc4bf5af468d939914b8f405c244","placeholder":"​","style":"IPY_MODEL_949bfb65e54a401891a4a18849d52f76","value":"Map: 100%"}},"c25b1f5cecec42c8ac53f1bb8c9fad82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6f7772dd9c48fe9c1d56560adf761e","max":20022,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3a42efe8f6749479c141c294d47b784","value":20022}},"05f0f47ad6564d58bb9d05b1e84c8857":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e42afd1ad2c4c6381e0fc0ecee4fc84","placeholder":"​","style":"IPY_MODEL_f27d8f2804db488cb87f3029c3293808","value":" 20022/20022 [00:07&lt;00:00, 4514.27 examples/s]"}},"7ab93e822e3947f0b5c714b5ec689db5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"435cbc4bf5af468d939914b8f405c244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"949bfb65e54a401891a4a18849d52f76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b6f7772dd9c48fe9c1d56560adf761e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a42efe8f6749479c141c294d47b784":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e42afd1ad2c4c6381e0fc0ecee4fc84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27d8f2804db488cb87f3029c3293808":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets\n!pip install bitsandbytes\n!pip install peft\n!pip install accelerate\n!pip install trl","metadata":{"id":"ULlwc_0qDhtk","outputId":"48d9ba76-1fab-419b-f35a-35d71c80f8dc","execution":{"iopub.status.busy":"2024-10-08T16:50:33.009299Z","iopub.execute_input":"2024-10-08T16:50:33.010087Z","iopub.status.idle":"2024-10-08T16:51:38.442758Z","shell.execute_reply.started":"2024-10-08T16:50:33.010046Z","shell.execute_reply":"2024-10-08T16:51:38.441677Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.1\nCollecting peft\n  Downloading peft-0.13.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.1-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.1\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting trl\n  Downloading trl-0.11.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.4.0)\nRequirement already satisfied: transformers>=4.40.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.45.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.34.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (3.0.1)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.40.0->trl) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nDownloading trl-0.11.2-py3-none-any.whl (316 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.11.2 tyro-0.8.11\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, DataCollatorForCompletionOnlyLM","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:51:38.445042Z","iopub.execute_input":"2024-10-08T16:51:38.446133Z","iopub.status.idle":"2024-10-08T16:51:58.316550Z","shell.execute_reply.started":"2024-10-08T16:51:38.446030Z","shell.execute_reply":"2024-10-08T16:51:58.315719Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:51:58.317734Z","iopub.execute_input":"2024-10-08T16:51:58.318396Z","iopub.status.idle":"2024-10-08T16:52:06.282550Z","shell.execute_reply.started":"2024-10-08T16:51:58.318349Z","shell.execute_reply":"2024-10-08T16:52:06.281580Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0916d29d8f2409b89bb9a9fe5181558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d3401b6c1c34950a83028c02edbde07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ef02ab7b70948198343f93a45e17b4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce7f21291b0a4346a1acc1e78270b0d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2726054e5841a185d4a7295a715f71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f589703bab4bcabd5981ecc81316c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db87f569ad884837826972d36db39229"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:06.284703Z","iopub.execute_input":"2024-10-08T16:52:06.285027Z","iopub.status.idle":"2024-10-08T16:52:10.789577Z","shell.execute_reply.started":"2024-10-08T16:52:06.284992Z","shell.execute_reply":"2024-10-08T16:52:10.788547Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/677 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825b1e25206f4db09980c5388b490d85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-e270777bb989ac86.parquet:   0%|          | 0.00/3.45M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d838a537614469294f9ea9fe21ed78b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50a0763cffb348ed96699dbfffbf2855"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Trainer with DataCollatorForCompletionOnlyLM\n\nEquivalent to PLW = 0.0","metadata":{}},{"cell_type":"code","source":"# def formatting_prompts_func(example):\n#     output_texts = []\n#     for i in range(len(example['instruction'])):\n#         text = f\"### Question: {example['instruction'][i]}\\n### Answer: {example['output'][i]}\"\n#         output_texts.append(text)\n#     return output_texts\n\ndef formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['instruction'])):\n        prompt = f\"### Question: {example['instruction'][i]}\\n\"\n        if example[\"input\"][i]:\n            prompt += f\"### Input: {example['input'][i]}\\n\"\n\n        prompt += \"### Answer:\"\n\n        text = prompt + example['output'][i]\n    \n        output_texts.append(text)\n    \n    return output_texts","metadata":{"id":"l0NU_FUtuRXD","outputId":"0720e6f7-67c5-4b37-e148-eef2d4ab49f4","execution":{"iopub.status.busy":"2024-10-08T14:16:18.062278Z","iopub.execute_input":"2024-10-08T14:16:18.062593Z","iopub.status.idle":"2024-10-08T14:16:18.068632Z","shell.execute_reply.started":"2024-10-08T14:16:18.062558Z","shell.execute_reply":"2024-10-08T14:16:18.067726Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"response_template = \"### Answer:\"\ncollator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n\ntrainer = SFTTrainer(\n    model,\n    train_dataset=dataset,\n    formatting_func=formatting_prompts_func,\n    data_collator=collator,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:07.163105Z","iopub.execute_input":"2024-10-07T21:52:07.163637Z","iopub.status.idle":"2024-10-07T21:52:11.092044Z","shell.execute_reply.started":"2024-10-07T21:52:07.163592Z","shell.execute_reply":"2024-10-07T21:52:11.091226Z"},"trusted":true},"execution_count":550,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:149: UserWarning: No `SFTConfig` passed, using `output_dir=tmp_trainer`.\n  warnings.warn(f\"No `SFTConfig` passed, using `output_dir={output_dir}`.\")\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dbeb8cff8e04237a0fa6a42d1edffdf"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"id":"8mJJOeAdDZdb","outputId":"d33d7c0b-5a36-4df4-b14a-36193fdc949d","execution":{"iopub.status.busy":"2024-10-07T21:52:11.093681Z","iopub.execute_input":"2024-10-07T21:52:11.094012Z","iopub.status.idle":"2024-10-07T21:52:11.099575Z","shell.execute_reply.started":"2024-10-07T21:52:11.093977Z","shell.execute_reply":"2024-10-07T21:52:11.098737Z"},"trusted":true},"execution_count":551,"outputs":[{"execution_count":551,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output'],\n    num_rows: 20022\n})"},"metadata":{}}]},{"cell_type":"code","source":"masked1 = trainer.data_collator.torch_call([trainer.train_dataset[0]])\nmasked1","metadata":{"id":"to_OywprEBPN","outputId":"d4fe8a84-e2d0-458b-d417-7183e259bea7","execution":{"iopub.status.busy":"2024-10-07T21:52:11.100769Z","iopub.execute_input":"2024-10-07T21:52:11.101073Z","iopub.status.idle":"2024-10-07T21:52:11.136996Z","shell.execute_reply.started":"2024-10-07T21:52:11.101042Z","shell.execute_reply":"2024-10-07T21:52:11.136056Z"},"trusted":true},"execution_count":552,"outputs":[{"execution_count":552,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]])}"},"metadata":{}}]},{"cell_type":"code","source":"masked1['input_ids'][0]","metadata":{"id":"xk4ABzyiK2zx","outputId":"207e5947-c70f-4af0-dcf1-cb6dbe6cff03","execution":{"iopub.status.busy":"2024-10-07T21:52:11.138736Z","iopub.execute_input":"2024-10-07T21:52:11.139016Z","iopub.status.idle":"2024-10-07T21:52:11.146405Z","shell.execute_reply.started":"2024-10-07T21:52:11.138986Z","shell.execute_reply":"2024-10-07T21:52:11.145587Z"},"trusted":true},"execution_count":553,"outputs":[{"execution_count":553,"output_type":"execute_result","data":{"text/plain":"tensor([    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n         2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n         5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n        31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n         1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n            8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n         1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n        12606,   176,  2055,   155,  3226,  1178])"},"metadata":{}}]},{"cell_type":"code","source":"masked1['attention_mask'][0]","metadata":{"id":"A7YR_671QZI2","outputId":"03bac2c3-e0fd-4e87-9753-bd2a6c7fff94","execution":{"iopub.status.busy":"2024-10-07T21:52:13.377998Z","iopub.execute_input":"2024-10-07T21:52:13.378401Z","iopub.status.idle":"2024-10-07T21:52:13.389520Z","shell.execute_reply.started":"2024-10-07T21:52:13.378353Z","shell.execute_reply":"2024-10-07T21:52:13.388502Z"},"trusted":true},"execution_count":554,"outputs":[{"execution_count":554,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"masked1['labels'][0]","metadata":{"id":"Z4rOYB--QqCs","outputId":"fb624ebd-7dc8-4fdc-818b-10bf25adcc48","execution":{"iopub.status.busy":"2024-10-07T21:52:14.318331Z","iopub.execute_input":"2024-10-07T21:52:14.318720Z","iopub.status.idle":"2024-10-07T21:52:14.327173Z","shell.execute_reply.started":"2024-10-07T21:52:14.318688Z","shell.execute_reply":"2024-10-07T21:52:14.326234Z"},"trusted":true},"execution_count":555,"outputs":[{"execution_count":555,"output_type":"execute_result","data":{"text/plain":"tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n         1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n            8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n         1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n        12606,   176,  2055,   155,  3226,  1178])"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode([9232,   856,  1640,\n         1178,  3256, 50118,  1437,  1437,  1437, 49434, 50118,  1437,  1437,\n         1437, 29072,    10,  2167,  8135,     8,  9108,    10,  2167,  4195,\n          634,   143, 30412,  5990, 50118,  1437,  1437,  1437, 49434, 50118,\n         1437,  1437,  1437,   671,  3023, 12606,   176,  2055,   155,  3226,\n         1178])","metadata":{"id":"6iJajraVQ5Vq","outputId":"783d7ae3-aaaf-4b97-e973-94eb1ca2bf97","execution":{"iopub.status.busy":"2024-10-07T21:52:15.694602Z","iopub.execute_input":"2024-10-07T21:52:15.695058Z","iopub.status.idle":"2024-10-07T21:52:15.710368Z","shell.execute_reply.started":"2024-10-07T21:52:15.695015Z","shell.execute_reply":"2024-10-07T21:52:15.709470Z"},"trusted":true},"execution_count":556,"outputs":[{"execution_count":556,"output_type":"execute_result","data":{"text/plain":"'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'"},"metadata":{}}]},{"cell_type":"code","source":"dataset[0]['output']","metadata":{"id":"FSLo0klKRFMK","outputId":"1d665340-b984-44bc-dd3b-fae72eb9f386","execution":{"iopub.status.busy":"2024-10-07T21:52:16.702215Z","iopub.execute_input":"2024-10-07T21:52:16.702623Z","iopub.status.idle":"2024-10-07T21:52:16.709242Z","shell.execute_reply.started":"2024-10-07T21:52:16.702584Z","shell.execute_reply":"2024-10-07T21:52:16.708311Z"},"trusted":true},"execution_count":557,"outputs":[{"execution_count":557,"output_type":"execute_result","data":{"text/plain":"'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'"},"metadata":{}}]},{"cell_type":"code","source":"model.device","metadata":{"id":"B3SF6OtPRMRd","outputId":"3d938982-2778-4b78-c818-58b7bea2a44a","execution":{"iopub.status.busy":"2024-10-07T21:52:17.506984Z","iopub.execute_input":"2024-10-07T21:52:17.507836Z","iopub.status.idle":"2024-10-07T21:52:17.513418Z","shell.execute_reply.started":"2024-10-07T21:52:17.507793Z","shell.execute_reply":"2024-10-07T21:52:17.512492Z"},"trusted":true},"execution_count":558,"outputs":[{"execution_count":558,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"masked1 = masked1.to(model.device)\nmasked1","metadata":{"id":"THf_4CIrS-nv","outputId":"8ae54770-6926-495e-ee27-7f4dd8766d44","execution":{"iopub.status.busy":"2024-10-07T21:52:18.351075Z","iopub.execute_input":"2024-10-07T21:52:18.351473Z","iopub.status.idle":"2024-10-07T21:52:18.364237Z","shell.execute_reply.started":"2024-10-07T21:52:18.351436Z","shell.execute_reply":"2024-10-07T21:52:18.363391Z"},"trusted":true},"execution_count":559,"outputs":[{"execution_count":559,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]], device='cuda:0')}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.compute_loss(model, masked1)","metadata":{"id":"1IcoeyopTVnO","outputId":"c2a02db3-54d2-42c1-ddac-e19d4b84ba25","execution":{"iopub.status.busy":"2024-10-07T21:52:19.025252Z","iopub.execute_input":"2024-10-07T21:52:19.025624Z","iopub.status.idle":"2024-10-07T21:52:19.069259Z","shell.execute_reply.started":"2024-10-07T21:52:19.025590Z","shell.execute_reply":"2024-10-07T21:52:19.068392Z"},"trusted":true},"execution_count":560,"outputs":[{"execution_count":560,"output_type":"execute_result","data":{"text/plain":"tensor(2.3737, device='cuda:0', grad_fn=<NllLossBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Trainer with PLW = 1 (default)","metadata":{}},{"cell_type":"code","source":"# def formatting_prompts_func(example):\n#     output_texts = []\n#     for i in range(len(example['instruction'])):\n#         text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n#         output_texts.append(text)\n#     return output_texts\n\ndef formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['instruction'])):\n        prompt = f\"### Question: {example['instruction'][i]}\\n\"\n        if example[\"input\"][i]:\n            prompt += f\"### Input: {example['input'][i]}\\n\"\n\n        prompt += \"### Answer:\"\n\n        text = prompt + example['output'][i]\n    \n        output_texts.append(text)\n    \n    return output_texts","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:42.237704Z","iopub.execute_input":"2024-10-07T21:52:42.238091Z","iopub.status.idle":"2024-10-07T21:52:42.244617Z","shell.execute_reply.started":"2024-10-07T21:52:42.238051Z","shell.execute_reply":"2024-10-07T21:52:42.243669Z"},"trusted":true},"execution_count":561,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:43.657880Z","iopub.execute_input":"2024-10-07T21:52:43.658267Z","iopub.status.idle":"2024-10-07T21:52:43.664293Z","shell.execute_reply.started":"2024-10-07T21:52:43.658227Z","shell.execute_reply":"2024-10-07T21:52:43.663373Z"},"trusted":true},"execution_count":562,"outputs":[{"execution_count":562,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output'],\n    num_rows: 20022\n})"},"metadata":{}}]},{"cell_type":"code","source":"trainer2 = SFTTrainer(\n    model,\n    train_dataset=dataset,\n    formatting_func=formatting_prompts_func,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:46.501899Z","iopub.execute_input":"2024-10-07T21:52:46.502756Z","iopub.status.idle":"2024-10-07T21:52:46.831406Z","shell.execute_reply.started":"2024-10-07T21:52:46.502713Z","shell.execute_reply":"2024-10-07T21:52:46.830496Z"},"trusted":true},"execution_count":563,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:149: UserWarning: No `SFTConfig` passed, using `output_dir=tmp_trainer`.\n  warnings.warn(f\"No `SFTConfig` passed, using `output_dir={output_dir}`.\")\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"masked = trainer2.data_collator.torch_call([trainer2.train_dataset[0]])\nmasked","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:48.820690Z","iopub.execute_input":"2024-10-07T21:52:48.821501Z","iopub.status.idle":"2024-10-07T21:52:48.831326Z","shell.execute_reply.started":"2024-10-07T21:52:48.821456Z","shell.execute_reply":"2024-10-07T21:52:48.830463Z"},"trusted":true},"execution_count":564,"outputs":[{"execution_count":564,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]]), 'labels': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]])}"},"metadata":{}}]},{"cell_type":"code","source":"masked = masked.to(model.device)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:49.977228Z","iopub.execute_input":"2024-10-07T21:52:49.978002Z","iopub.status.idle":"2024-10-07T21:52:49.982960Z","shell.execute_reply.started":"2024-10-07T21:52:49.977958Z","shell.execute_reply":"2024-10-07T21:52:49.981873Z"},"trusted":true},"execution_count":565,"outputs":[]},{"cell_type":"code","source":"masked","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:50.807911Z","iopub.execute_input":"2024-10-07T21:52:50.808645Z","iopub.status.idle":"2024-10-07T21:52:50.819856Z","shell.execute_reply.started":"2024-10-07T21:52:50.808605Z","shell.execute_reply":"2024-10-07T21:52:50.818865Z"},"trusted":true},"execution_count":566,"outputs":[{"execution_count":566,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]], device='cuda:0')}"},"metadata":{}}]},{"cell_type":"code","source":"loss, outputs = trainer2.compute_loss(model, masked, return_outputs=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:51.836077Z","iopub.execute_input":"2024-10-07T21:52:51.836702Z","iopub.status.idle":"2024-10-07T21:52:51.877577Z","shell.execute_reply.started":"2024-10-07T21:52:51.836658Z","shell.execute_reply":"2024-10-07T21:52:51.876585Z"},"trusted":true},"execution_count":567,"outputs":[]},{"cell_type":"code","source":"loss","metadata":{"execution":{"iopub.status.busy":"2024-10-07T21:52:52.789102Z","iopub.execute_input":"2024-10-07T21:52:52.790001Z","iopub.status.idle":"2024-10-07T21:52:52.797196Z","shell.execute_reply.started":"2024-10-07T21:52:52.789957Z","shell.execute_reply":"2024-10-07T21:52:52.796016Z"},"trusted":true},"execution_count":568,"outputs":[{"execution_count":568,"output_type":"execute_result","data":{"text/plain":"tensor(3.1216, device='cuda:0', grad_fn=<NllLossBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Custom Trainer for PLW\n\nTests:\n1. PLW = 1.0 => Should give the same output as default huggingface SFTTrainer\n2. PLW = 0.0 => Should give the same output as SFTTrainer with DataCollatorForCompletionOnlyLM","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport warnings","metadata":{"id":"7BqTOXOPYTxq","execution":{"iopub.status.busy":"2024-10-08T14:16:18.069819Z","iopub.execute_input":"2024-10-08T14:16:18.072661Z","iopub.status.idle":"2024-10-08T14:16:20.223929Z","shell.execute_reply.started":"2024-10-08T14:16:18.072626Z","shell.execute_reply":"2024-10-08T14:16:20.222920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from typing import Any, Dict, List, Literal, Optional, Tuple, Union","metadata":{"execution":{"iopub.status.busy":"2024-10-08T14:16:20.225218Z","iopub.execute_input":"2024-10-08T14:16:20.226139Z","iopub.status.idle":"2024-10-08T14:16:20.234180Z","shell.execute_reply.started":"2024-10-08T14:16:20.226103Z","shell.execute_reply":"2024-10-08T14:16:20.233293Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:55.419677Z","iopub.execute_input":"2024-10-08T12:53:55.420176Z","iopub.status.idle":"2024-10-08T12:53:55.427880Z","shell.execute_reply.started":"2024-10-08T12:53:55.420127Z","shell.execute_reply":"2024-10-08T12:53:55.427092Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SFTTrainerWithPLW(SFTTrainer):\n    def __init__(self, *args, plw=1.0, response_template_tokens, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.plw = plw\n        self.response_template_tokens = response_template_tokens\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n        logits = outputs.get(\"logits\")\n        labels = inputs.pop(\"labels\")\n\n        # Initialize the weights matrix with ones, keeping the same shape as labels\n        weights = torch.ones_like(labels, dtype=torch.float32)\n\n        batch_size = labels.shape[0]\n        labels_length = labels.shape[1]\n        response_tokens_length = len(self.response_template_tokens)\n\n        # Iterate through each example in the batch to find the completion_start_idx\n        for batch_idx in range(batch_size):\n            completion_start_idx = None\n\n            # Search for response_tokens in labels for the current batch element\n            for i in range(labels_length - response_tokens_length + 1):\n                if labels[batch_idx, i:i + response_tokens_length].tolist() == self.response_template_tokens:\n                    completion_start_idx = i + response_tokens_length - 1\n                    break\n\n            # If we found completion_start_idx, modify weights for the current batch element\n            if completion_start_idx is not None:\n                weights[batch_idx, :completion_start_idx + 1] = self.plw\n\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        shift_weights = weights[..., 1:].contiguous()\n\n        shift_labels = shift_labels.to(shift_logits.device)\n        shift_weights = shift_weights.to(shift_logits.device)\n\n        # per-token losses\n        loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n        token_losses = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), \n                                shift_labels.view(-1))\n\n        # Compute weighted average of losses\n        loss = (token_losses.float() @ shift_weights.view(-1).float()) / shift_weights.sum()\n        return (loss, outputs) if return_outputs else loss","metadata":{"id":"y5VEZE1qTZq0","execution":{"iopub.status.busy":"2024-10-08T12:53:55.429122Z","iopub.execute_input":"2024-10-08T12:53:55.429488Z","iopub.status.idle":"2024-10-08T12:53:55.442169Z","shell.execute_reply.started":"2024-10-08T12:53:55.429445Z","shell.execute_reply":"2024-10-08T12:53:55.441091Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"response_template = \"### Answer:\"\nresponse_template_tokens = tokenizer.encode(response_template)[2:]\nresponse_template_tokens","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:55.444784Z","iopub.execute_input":"2024-10-08T12:53:55.445093Z","iopub.status.idle":"2024-10-08T12:53:55.462946Z","shell.execute_reply.started":"2024-10-08T12:53:55.445034Z","shell.execute_reply":"2024-10-08T12:53:55.462036Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[31652, 35]"},"metadata":{}}]},{"cell_type":"code","source":"def formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['instruction'])):\n        prompt = f\"### Question: {example['instruction'][i]}\\n\"\n        if example[\"input\"][i]:\n            prompt += f\"### Input: {example['input'][i]}\\n\"\n\n        prompt += \"### Answer:\"\n\n        text = prompt + example['output'][i]\n    \n        output_texts.append(text)\n    \n    return output_texts","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:55.464080Z","iopub.execute_input":"2024-10-08T12:53:55.464447Z","iopub.status.idle":"2024-10-08T12:53:55.469922Z","shell.execute_reply.started":"2024-10-08T12:53:55.464403Z","shell.execute_reply":"2024-10-08T12:53:55.468863Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"trainer3 = SFTTrainerWithPLW(\n    model,\n    train_dataset=dataset,\n    formatting_func=formatting_prompts_func,\n    response_template_tokens=response_template_tokens,\n    plw=0.7\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:32.468969Z","iopub.execute_input":"2024-10-08T12:54:32.469436Z","iopub.status.idle":"2024-10-08T12:54:32.780841Z","shell.execute_reply.started":"2024-10-08T12:54:32.469394Z","shell.execute_reply":"2024-10-08T12:54:32.779884Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:149: UserWarning: No `SFTConfig` passed, using `output_dir=tmp_trainer`.\n  warnings.warn(f\"No `SFTConfig` passed, using `output_dir={output_dir}`.\")\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"masked = trainer3.data_collator.torch_call([trainer3.train_dataset[0]])\nmasked","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:33.437142Z","iopub.execute_input":"2024-10-08T12:54:33.437591Z","iopub.status.idle":"2024-10-08T12:54:33.447836Z","shell.execute_reply.started":"2024-10-08T12:54:33.437551Z","shell.execute_reply":"2024-10-08T12:54:33.446951Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]]), 'labels': tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]])}"},"metadata":{}}]},{"cell_type":"code","source":"masked = masked.to(model.device)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:34.738541Z","iopub.execute_input":"2024-10-08T12:54:34.738928Z","iopub.status.idle":"2024-10-08T12:54:34.744091Z","shell.execute_reply.started":"2024-10-08T12:54:34.738891Z","shell.execute_reply":"2024-10-08T12:54:34.743116Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"masked['labels']","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:35.787655Z","iopub.execute_input":"2024-10-08T12:54:35.788032Z","iopub.status.idle":"2024-10-08T12:54:35.797251Z","shell.execute_reply.started":"2024-10-08T12:54:35.787996Z","shell.execute_reply":"2024-10-08T12:54:35.796329Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor([[    2, 48134, 15680,    35, 21384,    10,  5043,    14,  1239,    10,\n          2167,  8135,     8,  9108,    10,  2167,  4195,   634,   143, 30412,\n          5990,     4, 21062, 12337,  3260,    11, 31886,     4, 50118, 48134,\n         31652,    35,  9232,   856,  1640,  1178,  3256, 50118,  1437,  1437,\n          1437, 49434, 50118,  1437,  1437,  1437, 29072,    10,  2167,  8135,\n             8,  9108,    10,  2167,  4195,   634,   143, 30412,  5990, 50118,\n          1437,  1437,  1437, 49434, 50118,  1437,  1437,  1437,   671,  3023,\n         12606,   176,  2055,   155,  3226,  1178]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"loss, outputs = trainer3.compute_loss(model, masked, return_outputs=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:36.786684Z","iopub.execute_input":"2024-10-08T12:54:36.787586Z","iopub.status.idle":"2024-10-08T12:54:36.827511Z","shell.execute_reply.started":"2024-10-08T12:54:36.787541Z","shell.execute_reply":"2024-10-08T12:54:36.826593Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"loss","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:37.485009Z","iopub.execute_input":"2024-10-08T12:54:37.485867Z","iopub.status.idle":"2024-10-08T12:54:37.493889Z","shell.execute_reply.started":"2024-10-08T12:54:37.485825Z","shell.execute_reply":"2024-10-08T12:54:37.492839Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensor(2.9714, device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### PLW With Custom Data Collator","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-08T14:16:20.235400Z","iopub.execute_input":"2024-10-08T14:16:20.235787Z","iopub.status.idle":"2024-10-08T14:16:20.245246Z","shell.execute_reply.started":"2024-10-08T14:16:20.235744Z","shell.execute_reply":"2024-10-08T14:16:20.244384Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\nfrom typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:41.607409Z","iopub.execute_input":"2024-10-08T12:54:41.607797Z","iopub.status.idle":"2024-10-08T12:54:41.612376Z","shell.execute_reply.started":"2024-10-08T12:54:41.607762Z","shell.execute_reply":"2024-10-08T12:54:41.611466Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class DataCollatorForPLW(DataCollatorForLanguageModeling):\n\n    def __init__(\n        self,\n        response_template: Union[str, List[int]],\n        instruction_template: Optional[Union[str, List[int]]] = None,\n        *args,\n        mlm: bool = False,\n        ignore_index: int = -100,\n        padding_free: bool = False,\n        **kwargs,\n    ):\n        super().__init__(*args, mlm=mlm, **kwargs)\n\n        self.instruction_template = instruction_template\n        if isinstance(instruction_template, str):\n            # The user provides a string, must tokenize\n            self.instruction_token_ids = self.tokenizer.encode(self.instruction_template, add_special_tokens=False)\n        else:\n            # The user already provides the token ids\n            self.instruction_token_ids = instruction_template\n\n        self.response_template = response_template\n        if isinstance(response_template, str):\n            # The user provides a string, must tokenize\n            self.response_token_ids = self.tokenizer.encode(self.response_template, add_special_tokens=False)\n        else:\n            # The user already provides the token ids\n            self.response_token_ids = response_template\n\n        if not self.mlm and self.instruction_template and self.tokenizer.pad_token_id == self.tokenizer.eos_token_id:\n            warnings.warn(\n                \"The pad_token_id and eos_token_id values of this tokenizer are identical. \"\n                \"If you are planning for multi-turn training, \"\n                \"it can result in the model continuously generating questions and answers without eos token. \"\n                \"To avoid this, set the pad_token_id to a different value.\"\n            )\n\n        self.ignore_index = ignore_index\n        self.padding_free = padding_free\n\n    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n        batch = super().torch_call(examples)\n        \n        # Initialize the \"weights\" column to be all ones\n        batch_size = batch[\"labels\"].shape[0]\n        seq_len = batch[\"labels\"].shape[1]\n        batch[\"prompt_mask\"] = torch.zeros((batch_size, seq_len), dtype=torch.float32)\n\n\n        if self.instruction_template is None:\n            for i in range(len(examples)):\n                response_token_ids_start_idx = None\n\n                for idx in np.where(batch[\"labels\"][i] == self.response_token_ids[0])[0]:\n                    # `response_token_ids` is `'### Response:\\n'`, here we are just making sure that the token IDs match\n                    if (\n                        self.response_token_ids\n                        == batch[\"labels\"][i][idx : idx + len(self.response_token_ids)].tolist()\n                    ):\n                        response_token_ids_start_idx = idx\n\n                if response_token_ids_start_idx is None:\n                    warnings.warn(\n                        f\"Could not find response key `{self.response_template}` in the \"\n                        f'following instance: {self.tokenizer.decode(batch[\"input_ids\"][i])} '\n                        f\"This instance will be ignored in loss calculation. \"\n                        f\"Note, if this happens often, consider increasing the `max_seq_length`.\"\n                    )\n                    batch[\"prompt_mask\"][i, :] = 1\n                else:\n                    response_token_ids_end_idx = response_token_ids_start_idx + len(self.response_token_ids)\n\n                    # Make pytorch loss function ignore all tokens up through the end of the response key\n                    batch[\"prompt_mask\"][i, :response_token_ids_end_idx] = 1\n\n        else:\n            for i in range(len(examples)):\n                response_token_ids_idxs = []\n                human_token_ids_idxs = []\n\n                for assistant_idx in np.where(batch[\"labels\"][i] == self.response_token_ids[0])[0]:\n                    # find the indexes of the start of a response.\n                    if (\n                        self.response_token_ids\n                        == batch[\"labels\"][i][assistant_idx : assistant_idx + len(self.response_token_ids)].tolist()\n                    ):\n                        response_token_ids_idxs.append(assistant_idx + len(self.response_token_ids))\n\n                if len(response_token_ids_idxs) == 0:\n                    warnings.warn(\n                        f\"Could not find response key `{self.response_template}` in the \"\n                        f'following instance: {self.tokenizer.decode(batch[\"input_ids\"][i])} '\n                        f\"This instance will be ignored in loss calculation. \"\n                        f\"Note, if this happens often, consider increasing the `max_seq_length`.\"\n                    )\n                    batch[\"prompt_mask\"][i, :] = 1\n\n                human_token_ids = self.instruction_token_ids\n                for human_idx in np.where(batch[\"labels\"][i] == human_token_ids[0])[0]:\n                    # find the indexes of the start of a human answer.\n                    if human_token_ids == batch[\"labels\"][i][human_idx : human_idx + len(human_token_ids)].tolist():\n                        human_token_ids_idxs.append(human_idx)\n\n                if len(human_token_ids_idxs) == 0:\n                    warnings.warn(\n                        f\"Could not find instruction key `{self.instruction_template}` in the \"\n                        f'following instance: {self.tokenizer.decode(batch[\"input_ids\"][i])} '\n                        f\"This instance will be ignored in loss calculation. \"\n                        f\"Note, if this happens often, consider increasing the `max_seq_length`.\"\n                    )\n                    batch[\"prompt_mask\"][i, :] = 1\n\n                if (\n                    len(human_token_ids_idxs) > 0\n                    and len(response_token_ids_idxs) > 0\n                    and human_token_ids_idxs[0] > response_token_ids_idxs[0]\n                ):\n                    human_token_ids_idxs = [0] + human_token_ids_idxs\n\n                for idx, (start, end) in enumerate(zip(human_token_ids_idxs, response_token_ids_idxs)):\n                    # Make pytorch loss function ignore all non response tokens\n                    if idx != 0:\n                        batch[\"prompt_mask\"][i, start:end] = 1\n                    else:\n                        batch[\"prompt_mask\"][i, :end] = 1\n\n                if len(response_token_ids_idxs) < len(human_token_ids_idxs):\n                    batch[\"prompt_mask\"][i, human_token_ids_idxs[-1] :] = 1\n\n        if self.padding_free:\n            # remove padding, `attention_mask` and add `position_ids`\n            attn_mask = batch.pop(\"attention_mask\")\n            batch[\"input_ids\"] = batch[\"input_ids\"][attn_mask.bool()].unsqueeze(0)\n            batch[\"position_ids\"] = attn_mask.cumsum(1)[attn_mask.bool()].unsqueeze(0) - 1\n            batch[\"labels\"] = batch[\"labels\"][attn_mask.bool()].unsqueeze(0)\n            batch[\"prompt_mask\"] = batch[\"prompt_mask\"][attn_mask.bool()].unsqueeze(0)\n            batch[\"labels\"][batch[\"position_ids\"] == 0] = self.ignore_index\n            batch[\"prompt_mask\"][batch[\"position_ids\"] == 0] = 1\n            \n        return batch","metadata":{"id":"5E1RdkkgaWnt","execution":{"iopub.status.busy":"2024-10-08T12:54:42.869541Z","iopub.execute_input":"2024-10-08T12:54:42.870133Z","iopub.status.idle":"2024-10-08T12:54:42.898030Z","shell.execute_reply.started":"2024-10-08T12:54:42.870090Z","shell.execute_reply":"2024-10-08T12:54:42.897107Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class SFTTrainerWithPLWCollator(SFTTrainer):\n    def __init__(self, *args, plw=1.0, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.plw = plw\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n        logits = outputs.get(\"logits\")\n        labels = inputs.pop(\"labels\")\n        \n        prompt_mask = inputs[\"prompt_mask\"]\n        weights = torch.where(prompt_mask == 1, self.plw, torch.tensor(1.0, device=prompt_mask.device))\n        \n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        shift_weights = weights[..., 1:].contiguous()\n\n        shift_labels = shift_labels.to(shift_logits.device)\n        shift_weights = shift_weights.to(shift_logits.device)\n\n        # per-token losses\n        loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n        token_losses = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), \n                                shift_labels.view(-1))\n\n        # Compute weighted average of losses\n        loss = (token_losses.float() @ shift_weights.view(-1).float()) / shift_weights.sum()\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:43.851344Z","iopub.execute_input":"2024-10-08T12:54:43.851734Z","iopub.status.idle":"2024-10-08T12:54:43.863355Z","shell.execute_reply.started":"2024-10-08T12:54:43.851698Z","shell.execute_reply":"2024-10-08T12:54:43.862307Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"response_template = \"### Answer:\"","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:45.334957Z","iopub.execute_input":"2024-10-08T12:54:45.335858Z","iopub.status.idle":"2024-10-08T12:54:45.339951Z","shell.execute_reply.started":"2024-10-08T12:54:45.335816Z","shell.execute_reply":"2024-10-08T12:54:45.338908Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"response_template_token_ids = tokenizer.encode(response_template)[1:]\nresponse_template_token_ids","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:46.221629Z","iopub.execute_input":"2024-10-08T12:54:46.222008Z","iopub.status.idle":"2024-10-08T12:54:46.229203Z","shell.execute_reply.started":"2024-10-08T12:54:46.221972Z","shell.execute_reply":"2024-10-08T12:54:46.228324Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[48134, 31652, 35]"},"metadata":{}}]},{"cell_type":"code","source":"plw_collator = DataCollatorForPLW(response_template_token_ids, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:47.352212Z","iopub.execute_input":"2024-10-08T12:54:47.352605Z","iopub.status.idle":"2024-10-08T12:54:47.357430Z","shell.execute_reply.started":"2024-10-08T12:54:47.352568Z","shell.execute_reply":"2024-10-08T12:54:47.356505Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['instruction'])):\n        prompt = f\"### Question: {example['instruction'][i]}\\n\"\n        if example[\"input\"][i]:\n            prompt += f\"### Input: {example['input'][i]}\\n\"\n\n        prompt += \"### Answer:\"\n\n        text = prompt + example['output'][i]\n    \n        output_texts.append(text)\n    \n    return output_texts","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:48.176859Z","iopub.execute_input":"2024-10-08T12:54:48.177271Z","iopub.status.idle":"2024-10-08T12:54:48.183634Z","shell.execute_reply.started":"2024-10-08T12:54:48.177233Z","shell.execute_reply":"2024-10-08T12:54:48.182555Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"trainer4 = SFTTrainerWithPLWCollator(\n    model,\n    train_dataset=dataset,\n    formatting_func=formatting_prompts_func,\n    data_collator=plw_collator,\n#     compute_metrics=prepare_compute_metrics(response_template_token_ids),\n#     preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n    plw=0.7\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:52.523788Z","iopub.execute_input":"2024-10-08T12:54:52.524564Z","iopub.status.idle":"2024-10-08T12:54:52.826219Z","shell.execute_reply.started":"2024-10-08T12:54:52.524518Z","shell.execute_reply":"2024-10-08T12:54:52.825112Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:149: UserWarning: No `SFTConfig` passed, using `output_dir=tmp_trainer`.\n  warnings.warn(f\"No `SFTConfig` passed, using `output_dir={output_dir}`.\")\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"masked = trainer4.data_collator.torch_call([trainer4.train_dataset[0]])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:56.906953Z","iopub.execute_input":"2024-10-08T12:54:56.907812Z","iopub.status.idle":"2024-10-08T12:54:56.914582Z","shell.execute_reply.started":"2024-10-08T12:54:56.907772Z","shell.execute_reply":"2024-10-08T12:54:56.913745Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"masked = masked.to(model.device)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:58.024857Z","iopub.execute_input":"2024-10-08T12:54:58.025770Z","iopub.status.idle":"2024-10-08T12:54:58.030516Z","shell.execute_reply.started":"2024-10-08T12:54:58.025728Z","shell.execute_reply":"2024-10-08T12:54:58.029452Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"loss, outputs = trainer4.compute_loss(model, masked, return_outputs=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:58.898959Z","iopub.execute_input":"2024-10-08T12:54:58.899393Z","iopub.status.idle":"2024-10-08T12:54:58.942725Z","shell.execute_reply.started":"2024-10-08T12:54:58.899356Z","shell.execute_reply":"2024-10-08T12:54:58.941964Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"loss","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:59.797579Z","iopub.execute_input":"2024-10-08T12:54:59.797953Z","iopub.status.idle":"2024-10-08T12:54:59.805738Z","shell.execute_reply.started":"2024-10-08T12:54:59.797917Z","shell.execute_reply":"2024-10-08T12:54:59.804824Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"tensor(2.9714, device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Another PLW Implementation","metadata":{}},{"cell_type":"markdown","source":"The idea here is to add prompt_mask and completion_mask as columns to the dataset, this requires setting `remove_unused_columns` to `False` in the `SFTConfig` so that these columns will not be lost during training. \n\nThe next step will be to used these columns to define custom metrices to calculate `prompt_loss` and `completion_loss` separetly. ","metadata":{}},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:10.790792Z","iopub.execute_input":"2024-10-08T16:52:10.791068Z","iopub.status.idle":"2024-10-08T16:52:10.798603Z","shell.execute_reply.started":"2024-10-08T16:52:10.791037Z","shell.execute_reply":"2024-10-08T16:52:10.797647Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output'],\n    num_rows: 20022\n})"},"metadata":{}}]},{"cell_type":"code","source":"def format_instruction(example):\n    prompt = f\"### Question: {example['instruction']}\\n\"\n    if example[\"input\"]:\n        prompt += f\"### Input: {example['input']}\\n\"\n    \n    prompt += \"### Answer:\"\n    \n    text = prompt + example['output']\n    \n    return {\n        'prompt': prompt,\n        'completion': example['output'],\n        'text': text\n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:10.799715Z","iopub.execute_input":"2024-10-08T16:52:10.799997Z","iopub.status.idle":"2024-10-08T16:52:11.092718Z","shell.execute_reply.started":"2024-10-08T16:52:10.799966Z","shell.execute_reply":"2024-10-08T16:52:11.091826Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ds = dataset.map(format_instruction)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:11.095163Z","iopub.execute_input":"2024-10-08T16:52:11.096088Z","iopub.status.idle":"2024-10-08T16:52:12.869405Z","shell.execute_reply.started":"2024-10-08T16:52:11.096016Z","shell.execute_reply":"2024-10-08T16:52:12.868443Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d64b461a0ab441f399f97627ccc3b5c9"}},"metadata":{}}]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.870670Z","iopub.execute_input":"2024-10-08T16:52:12.870971Z","iopub.status.idle":"2024-10-08T16:52:12.877131Z","shell.execute_reply.started":"2024-10-08T16:52:12.870938Z","shell.execute_reply":"2024-10-08T16:52:12.876017Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'input', 'output', 'prompt', 'completion', 'text'],\n    num_rows: 20022\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.878526Z","iopub.execute_input":"2024-10-08T16:52:12.878820Z","iopub.status.idle":"2024-10-08T16:52:12.923165Z","shell.execute_reply.started":"2024-10-08T16:52:12.878789Z","shell.execute_reply":"2024-10-08T16:52:12.922170Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'instruction': 'Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.',\n 'input': '',\n 'output': 'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x',\n 'prompt': '### Question: Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\\n### Answer:',\n 'completion': 'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x',\n 'text': '### Question: Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\\n### Answer:def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'}"},"metadata":{}}]},{"cell_type":"code","source":"ds = ds.remove_columns(['instruction', 'input', 'output'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.927629Z","iopub.execute_input":"2024-10-08T16:52:12.927925Z","iopub.status.idle":"2024-10-08T16:52:12.935047Z","shell.execute_reply.started":"2024-10-08T16:52:12.927895Z","shell.execute_reply":"2024-10-08T16:52:12.934319Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.936122Z","iopub.execute_input":"2024-10-08T16:52:12.936448Z","iopub.status.idle":"2024-10-08T16:52:12.945552Z","shell.execute_reply.started":"2024-10-08T16:52:12.936416Z","shell.execute_reply":"2024-10-08T16:52:12.944683Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'completion', 'text'],\n    num_rows: 20022\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.946735Z","iopub.execute_input":"2024-10-08T16:52:12.947091Z","iopub.status.idle":"2024-10-08T16:52:12.956350Z","shell.execute_reply.started":"2024-10-08T16:52:12.947052Z","shell.execute_reply":"2024-10-08T16:52:12.955447Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'prompt': '### Question: Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\\n### Answer:',\n 'completion': 'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x',\n 'text': '### Question: Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\\n### Answer:def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'}"},"metadata":{}}]},{"cell_type":"code","source":"max_seq_length = 1024","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.957508Z","iopub.execute_input":"2024-10-08T16:52:12.957817Z","iopub.status.idle":"2024-10-08T16:52:12.965055Z","shell.execute_reply.started":"2024-10-08T16:52:12.957787Z","shell.execute_reply":"2024-10-08T16:52:12.964319Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def tokenize_data(examples):\n    \n    # Tokenize without truncation\n    tokenized_prompt = tokenizer(examples['prompt'], padding=False, truncation=False)\n    tokenized_completion = tokenizer(examples['completion'], padding=False, truncation=False, add_special_tokens=False)\n    tokenized_text = tokenizer(examples['text'], padding=False, truncation=False)\n        \n    return {\n        'tokenized_prompt': tokenized_prompt['input_ids'],\n        'tokenized_completion': tokenized_completion['input_ids'],\n        'tokenized_text': tokenized_text['input_ids'],\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.966272Z","iopub.execute_input":"2024-10-08T16:52:12.967005Z","iopub.status.idle":"2024-10-08T16:52:12.975988Z","shell.execute_reply.started":"2024-10-08T16:52:12.966964Z","shell.execute_reply":"2024-10-08T16:52:12.975105Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Apply the tokenization to the dataset\ntokenized_dataset = ds.map(tokenize_data, batched=True)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:12.977158Z","iopub.execute_input":"2024-10-08T16:52:12.978044Z","iopub.status.idle":"2024-10-08T16:52:19.552108Z","shell.execute_reply.started":"2024-10-08T16:52:12.978011Z","shell.execute_reply":"2024-10-08T16:52:19.551267Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20059834ced949e1bfe7d6ebb90618bf"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'completion', 'text', 'tokenized_prompt', 'tokenized_completion', 'tokenized_text'],\n    num_rows: 20022\n})"},"metadata":{}}]},{"cell_type":"code","source":"len(tokenized_dataset[10]['tokenized_prompt']), len(tokenized_dataset[10]['tokenized_completion']), len(tokenized_dataset[10]['tokenized_text'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:19.553439Z","iopub.execute_input":"2024-10-08T16:52:19.553806Z","iopub.status.idle":"2024-10-08T16:52:19.563575Z","shell.execute_reply.started":"2024-10-08T16:52:19.553764Z","shell.execute_reply":"2024-10-08T16:52:19.562626Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(69, 23, 92)"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenized_dataset[10]['tokenized_text'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:19.564741Z","iopub.execute_input":"2024-10-08T16:52:19.565018Z","iopub.status.idle":"2024-10-08T16:52:19.705556Z","shell.execute_reply.started":"2024-10-08T16:52:19.564988Z","shell.execute_reply":"2024-10-08T16:52:19.704614Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[2, 48134, 15680, 35, 14686, 5, 2210, 3260, 7, 33, 10, 3989, 9, 36, 246, 6, 246, 43, 77, 41, 8932, 9, 1836, 36, 176, 6, 176, 43, 16, 14098, 14677, 4, 21062, 12337, 3260, 11, 31886, 4, 50118, 48134, 41327, 35, 6595, 295, 35187, 25, 46446, 50118, 50118, 6166, 5457, 46446, 4, 271, 10987, 1640, 306, 322, 23053, 5776, 1640, 176, 6, 176, 43, 50118, 48134, 31652, 35, 41975, 295, 35187, 25, 46446, 50118, 50118, 6166, 5457, 46446, 4, 271, 10987, 1640, 466, 322, 23053, 5776, 1640, 246, 6, 246, 43]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tokenized_dataset[10]['tokenized_prompt'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:19.706946Z","iopub.execute_input":"2024-10-08T16:52:19.707820Z","iopub.status.idle":"2024-10-08T16:52:19.716973Z","shell.execute_reply.started":"2024-10-08T16:52:19.707786Z","shell.execute_reply":"2024-10-08T16:52:19.716092Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[2, 48134, 15680, 35, 14686, 5, 2210, 3260, 7, 33, 10, 3989, 9, 36, 246, 6, 246, 43, 77, 41, 8932, 9, 1836, 36, 176, 6, 176, 43, 16, 14098, 14677, 4, 21062, 12337, 3260, 11, 31886, 4, 50118, 48134, 41327, 35, 6595, 295, 35187, 25, 46446, 50118, 50118, 6166, 5457, 46446, 4, 271, 10987, 1640, 306, 322, 23053, 5776, 1640, 176, 6, 176, 43, 50118, 48134, 31652, 35]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tokenized_dataset[10]['tokenized_completion'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:19.718126Z","iopub.execute_input":"2024-10-08T16:52:19.718491Z","iopub.status.idle":"2024-10-08T16:52:19.726760Z","shell.execute_reply.started":"2024-10-08T16:52:19.718459Z","shell.execute_reply":"2024-10-08T16:52:19.725893Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[41975, 295, 35187, 25, 46446, 50118, 50118, 6166, 5457, 46446, 4, 271, 10987, 1640, 466, 322, 23053, 5776, 1640, 246, 6, 246, 43]\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:19.727768Z","iopub.execute_input":"2024-10-08T16:52:19.728045Z","iopub.status.idle":"2024-10-08T16:52:19.739168Z","shell.execute_reply.started":"2024-10-08T16:52:19.728015Z","shell.execute_reply":"2024-10-08T16:52:19.738348Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assuming you have already created the 'tokenized_dataset'\n# Extract the lengths of tokenized_text\ntokenized_text_lengths = [len(tokens) for tokens in tokenized_dataset['tokenized_text']]\n\n# Calculate statistics\nmin_length = np.min(tokenized_text_lengths)\nmax_length = np.max(tokenized_text_lengths)\nq1 = np.percentile(tokenized_text_lengths, 25)\nmedian = np.percentile(tokenized_text_lengths, 50)\nq3 = np.percentile(tokenized_text_lengths, 75)\nmean_length = np.mean(tokenized_text_lengths)\n\n# Plot histogram\nplt.figure(figsize=(10, 6))\nplt.hist(tokenized_text_lengths, bins=30, color='skyblue', edgecolor='black')\n\n# Add title and labels\nplt.title('Histogram of Tokenized Text Lengths')\nplt.xlabel('Length of Tokenized Text')\nplt.ylabel('Frequency')\n\n# Add grid for clarity\nplt.grid(True)\n\n# Create a dummy plot for legend entries\nplt.text(0.95, 0.95, \n         f'Min: {min_length}\\nQ1: {q1}\\nMedian: {median}\\nQ3: {q3}\\nMean: {mean_length:.2f}\\nMax: {max_length}', \n         transform=plt.gca().transAxes, \n         verticalalignment='top', horizontalalignment='right', \n         bbox=dict(facecolor='white', alpha=0.5))\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:19.740303Z","iopub.execute_input":"2024-10-08T16:52:19.740582Z","iopub.status.idle":"2024-10-08T16:52:21.770471Z","shell.execute_reply.started":"2024-10-08T16:52:19.740552Z","shell.execute_reply":"2024-10-08T16:52:21.769571Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"max_seq_length = 512","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:21.771584Z","iopub.execute_input":"2024-10-08T16:52:21.771876Z","iopub.status.idle":"2024-10-08T16:52:21.776072Z","shell.execute_reply.started":"2024-10-08T16:52:21.771844Z","shell.execute_reply":"2024-10-08T16:52:21.775107Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Filter out sequences longer than max_seq_length\nfiltered_dataset = tokenized_dataset.filter(lambda example: len(example['tokenized_text']) <= max_seq_length)\nfiltered_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:21.777375Z","iopub.execute_input":"2024-10-08T16:52:21.777971Z","iopub.status.idle":"2024-10-08T16:52:25.161606Z","shell.execute_reply.started":"2024-10-08T16:52:21.777928Z","shell.execute_reply":"2024-10-08T16:52:25.160687Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/20022 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c781bc3717b94f9985f1111a9b731221"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'completion', 'text', 'tokenized_prompt', 'tokenized_completion', 'tokenized_text'],\n    num_rows: 19826\n})"},"metadata":{}}]},{"cell_type":"code","source":"filtered_dataset = filtered_dataset.remove_columns([\"prompt\", \"completion\", \"text\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:25.162696Z","iopub.execute_input":"2024-10-08T16:52:25.162988Z","iopub.status.idle":"2024-10-08T16:52:25.169790Z","shell.execute_reply.started":"2024-10-08T16:52:25.162956Z","shell.execute_reply":"2024-10-08T16:52:25.169025Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"filtered_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:25.170877Z","iopub.execute_input":"2024-10-08T16:52:25.171144Z","iopub.status.idle":"2024-10-08T16:52:25.183434Z","shell.execute_reply.started":"2024-10-08T16:52:25.171114Z","shell.execute_reply":"2024-10-08T16:52:25.182552Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokenized_prompt', 'tokenized_completion', 'tokenized_text'],\n    num_rows: 19826\n})"},"metadata":{}}]},{"cell_type":"code","source":"def pad_data(examples):\n    padded_prompt = tokenizer.pad({'input_ids': examples['tokenized_prompt']}, padding='max_length', max_length=max_seq_length)['input_ids']\n    padded_completion = tokenizer.pad({'input_ids': examples['tokenized_completion']}, padding='max_length', max_length=max_seq_length)['input_ids']\n    padded_text = tokenizer.pad({'input_ids': examples['tokenized_text']}, padding='max_length', max_length=max_seq_length)['input_ids']\n    \n    return {\n        'tokenized_prompt': padded_prompt,\n        'tokenized_completion': padded_completion,\n        'tokenized_text': padded_text\n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:25.184527Z","iopub.execute_input":"2024-10-08T16:52:25.184837Z","iopub.status.idle":"2024-10-08T16:52:25.192222Z","shell.execute_reply.started":"2024-10-08T16:52:25.184806Z","shell.execute_reply":"2024-10-08T16:52:25.191506Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"padded_dataset = filtered_dataset.map(pad_data, batched=True)\npadded_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:25.193382Z","iopub.execute_input":"2024-10-08T16:52:25.193726Z","iopub.status.idle":"2024-10-08T16:52:36.216153Z","shell.execute_reply.started":"2024-10-08T16:52:25.193684Z","shell.execute_reply":"2024-10-08T16:52:36.215232Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19826 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08e2be586c140c7a6e9295f82a9fd4b"}},"metadata":{}},{"name":"stderr","text":"You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokenized_prompt', 'tokenized_completion', 'tokenized_text'],\n    num_rows: 19826\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(padded_dataset[0]['tokenized_prompt'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:36.221600Z","iopub.execute_input":"2024-10-08T16:52:36.221928Z","iopub.status.idle":"2024-10-08T16:52:36.228233Z","shell.execute_reply.started":"2024-10-08T16:52:36.221894Z","shell.execute_reply":"2024-10-08T16:52:36.227202Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[2, 48134, 15680, 35, 21384, 10, 5043, 14, 1239, 10, 2167, 8135, 8, 9108, 10, 2167, 4195, 634, 143, 30412, 5990, 4, 21062, 12337, 3260, 11, 31886, 4, 50118, 48134, 31652, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(padded_dataset[0]['tokenized_completion'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:36.229540Z","iopub.execute_input":"2024-10-08T16:52:36.229917Z","iopub.status.idle":"2024-10-08T16:52:36.425961Z","shell.execute_reply.started":"2024-10-08T16:52:36.229870Z","shell.execute_reply":"2024-10-08T16:52:36.424934Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[9232, 856, 1640, 1178, 3256, 50118, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 29072, 10, 2167, 8135, 8, 9108, 10, 2167, 4195, 634, 143, 30412, 5990, 50118, 1437, 1437, 1437, 49434, 50118, 1437, 1437, 1437, 671, 3023, 12606, 176, 2055, 155, 3226, 1178, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:36.427332Z","iopub.execute_input":"2024-10-08T16:52:36.427985Z","iopub.status.idle":"2024-10-08T16:52:36.436877Z","shell.execute_reply.started":"2024-10-08T16:52:36.427940Z","shell.execute_reply":"2024-10-08T16:52:36.435930Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"# Add prompt_mask and completion_mask\ndef add_masks(example):\n    tokenized_text = example['tokenized_text']\n    tokenized_prompt = example['tokenized_prompt']\n    tokenized_completion = example['tokenized_completion']\n    \n    # Create a mask of zeros with the same size as tokenized_text\n    prompt_mask = torch.zeros_like(torch.tensor(tokenized_text))\n    completion_mask = torch.zeros_like(torch.tensor(tokenized_text))\n    \n    prompt_end_idx = next((i for i, token in enumerate(tokenized_prompt) if token == tokenizer.pad_token_id), len(tokenized_prompt))\n    completion_end_idx = next((i for i, token in enumerate(tokenized_completion) if token == tokenizer.pad_token_id), len(tokenized_prompt))\n    \n    for i in range(prompt_end_idx):\n        prompt_mask[i] = 1\n    for i in range(prompt_end_idx, prompt_end_idx + completion_end_idx):\n        completion_mask[i] = 1\n    \n    return {\n        'prompt_mask': prompt_mask,\n        'completion_mask': completion_mask\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:36.438120Z","iopub.execute_input":"2024-10-08T16:52:36.438639Z","iopub.status.idle":"2024-10-08T16:52:36.447481Z","shell.execute_reply.started":"2024-10-08T16:52:36.438596Z","shell.execute_reply":"2024-10-08T16:52:36.446712Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"masked_dataset = padded_dataset.map(add_masks)\nmasked_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:52:36.448658Z","iopub.execute_input":"2024-10-08T16:52:36.449346Z","iopub.status.idle":"2024-10-08T16:53:26.033065Z","shell.execute_reply.started":"2024-10-08T16:52:36.449296Z","shell.execute_reply":"2024-10-08T16:53:26.032245Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19826 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa905349f52466ca73b836f2ed915dd"}},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokenized_prompt', 'tokenized_completion', 'tokenized_text', 'prompt_mask', 'completion_mask'],\n    num_rows: 19826\n})"},"metadata":{}}]},{"cell_type":"code","source":"# tokenized_text => input_ids\n# tokenized_text => labels\n# prompt_mask => prompt_mask\n# completion_mask => completion_mask\n# attention_mask => all ones with same shape as input_ids\ndef map_features(example):\n    # Map 'tokenized_text' to 'input_ids' and 'labels'\n    input_ids = example['tokenized_text']\n    labels = example['tokenized_text']\n    prompt_mask = example['prompt_mask']\n    completion_mask = example['completion_mask']\n    \n    # Create attention mask (all ones, same shape as input_ids)\n    attention_mask = [1] * len(input_ids)\n    \n    # Return the updated dictionary\n    return {\n        'input_ids': input_ids,\n        'labels': labels,\n        'attention_mask': attention_mask,\n        'prompt_mask': example['prompt_mask'],\n        'completion_mask': example['completion_mask']\n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:53:26.034174Z","iopub.execute_input":"2024-10-08T16:53:26.034498Z","iopub.status.idle":"2024-10-08T16:53:26.040515Z","shell.execute_reply.started":"2024-10-08T16:53:26.034465Z","shell.execute_reply":"2024-10-08T16:53:26.039509Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"new_dataset = masked_dataset.map(map_features)\nnew_dataset = new_dataset.remove_columns(['tokenized_prompt', 'tokenized_completion', 'tokenized_text'])\nnew_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:53:26.042050Z","iopub.execute_input":"2024-10-08T16:53:26.042380Z","iopub.status.idle":"2024-10-08T16:53:58.844201Z","shell.execute_reply.started":"2024-10-08T16:53:26.042342Z","shell.execute_reply":"2024-10-08T16:53:58.843363Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19826 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b19386af07459dbd985c7667acf627"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt_mask', 'completion_mask', 'input_ids', 'labels', 'attention_mask'],\n    num_rows: 19826\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(new_dataset[0]['prompt_mask'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:53:58.845516Z","iopub.execute_input":"2024-10-08T16:53:58.845842Z","iopub.status.idle":"2024-10-08T16:53:58.852591Z","shell.execute_reply.started":"2024-10-08T16:53:58.845811Z","shell.execute_reply":"2024-10-08T16:53:58.851620Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(new_dataset[0]['completion_mask'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:53:58.854733Z","iopub.execute_input":"2024-10-08T16:53:58.855012Z","iopub.status.idle":"2024-10-08T16:54:00.895800Z","shell.execute_reply.started":"2024-10-08T16:53:58.854967Z","shell.execute_reply":"2024-10-08T16:54:00.894830Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test\nt1 = torch.tensor(new_dataset[0]['prompt_mask'])\nt2 = torch.tensor(new_dataset[0]['completion_mask'])\n\nt1 + t2","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.897126Z","iopub.execute_input":"2024-10-08T16:54:00.897553Z","iopub.status.idle":"2024-10-08T16:54:00.924994Z","shell.execute_reply.started":"2024-10-08T16:54:00.897509Z","shell.execute_reply":"2024-10-08T16:54:00.924128Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Implement Trainer class","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.926055Z","iopub.execute_input":"2024-10-08T16:54:00.926375Z","iopub.status.idle":"2024-10-08T16:54:00.930449Z","shell.execute_reply.started":"2024-10-08T16:54:00.926341Z","shell.execute_reply":"2024-10-08T16:54:00.929478Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class PLWTrainer(SFTTrainer):\n    def __init__(self, *args, plw=1.0, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.plw = plw\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n        logits = outputs.get(\"logits\")\n        labels = inputs.pop(\"labels\")\n        \n        prompt_mask = inputs.get(\"prompt_mask\")\n        completion_mask = inputs.get(\"completion_mask\")\n        \n        weights = self.plw * prompt_mask + completion_mask  \n        \n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n        shift_weights = weights[..., 1:].contiguous()\n\n        shift_labels = shift_labels.to(shift_logits.device)\n        shift_weights = shift_weights.to(shift_logits.device)\n\n        # per-token losses\n        loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n        token_losses = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), \n                                shift_labels.view(-1))\n\n        # Compute weighted average of losses\n        loss = (token_losses.float() @ shift_weights.view(-1).float()) / shift_weights.sum()\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.931620Z","iopub.execute_input":"2024-10-08T16:54:00.931883Z","iopub.status.idle":"2024-10-08T16:54:00.942589Z","shell.execute_reply.started":"2024-10-08T16:54:00.931853Z","shell.execute_reply":"2024-10-08T16:54:00.941722Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# preprocess_logits_for_metrics\n# This function will pass token predictions and token losses to the custom metrics that will be defined later\ndef preprocess_logits_for_metrics(logits, labels):\n    token_preds = logits.argmax(-1)[..., :-1]\n\n    # compute per-token losses\n    loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n    shift_logits = logits[..., :-1, :].contiguous()\n    shift_labels = labels[..., 1:].contiguous()\n    token_losses = loss_fct(shift_logits.transpose(1, 2), shift_labels)\n\n    # pass predictions and losses to compute_metrics()\n    predictions = (token_preds, token_losses)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.943650Z","iopub.execute_input":"2024-10-08T16:54:00.943936Z","iopub.status.idle":"2024-10-08T16:54:00.955058Z","shell.execute_reply.started":"2024-10-08T16:54:00.943905Z","shell.execute_reply":"2024-10-08T16:54:00.954112Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def define_compute_metrics(eval_dataset):\n    \n    prompt_mask = torch.tensor(eval_dataset['prompt_mask'], dtype=torch.float16)\n    completion_mask = torch.tensor(eval_dataset['completion_mask'], dtype=torch.float16)\n    \n    def compute_metrics(data):\n        token_predictions, token_losses = data.predictions\n        \n        token_losses = torch.tensor(token_losses, dtype=torch.float16)\n        \n        # Shift labels and masks\n        labels = data.label_ids[..., 1:]\n        shift_prompt_mask = prompt_mask[..., 1:]\n        shift_comp_mask = completion_mask[..., 1:]\n\n        \n         # average both losses (prompt and completion) over their respective tokens\n        prompt_loss = token_losses.reshape(-1) @ shift_prompt_mask.reshape(-1) / shift_prompt_mask.sum()\n        completion_loss = token_losses.reshape(-1) @ shift_comp_mask.reshape(-1) / shift_comp_mask.sum()\n\n        # compute response token accuracy\n#         nz = np.nonzero(shift_comp_mask)\n#         idx = np.where(np.isin(labels[nz], ABCD_token_ids))\n#         accuracy = np.mean(token_preds[nz][idx] == labels[nz][idx])\n\n        return {\n            'comp_loss': completion_loss,\n            'prompt_loss': prompt_loss,\n#             'acc': accuracy,\n        }\n    \n    return compute_metrics","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.956215Z","iopub.execute_input":"2024-10-08T16:54:00.956532Z","iopub.status.idle":"2024-10-08T16:54:00.965692Z","shell.execute_reply.started":"2024-10-08T16:54:00.956501Z","shell.execute_reply":"2024-10-08T16:54:00.964655Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"final_ds = new_dataset.train_test_split(test_size=0.1)\nfinal_ds","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.966929Z","iopub.execute_input":"2024-10-08T16:54:00.967310Z","iopub.status.idle":"2024-10-08T16:54:00.998543Z","shell.execute_reply.started":"2024-10-08T16:54:00.967268Z","shell.execute_reply":"2024-10-08T16:54:00.997669Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt_mask', 'completion_mask', 'input_ids', 'labels', 'attention_mask'],\n        num_rows: 17843\n    })\n    test: Dataset({\n        features: ['prompt_mask', 'completion_mask', 'input_ids', 'labels', 'attention_mask'],\n        num_rows: 1983\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"trainer5 = PLWTrainer(\n    model,\n    train_dataset=final_ds['train'],\n    eval_dataset=final_ds['test'],\n    plw=0.7,\n    args=TrainingArguments(\n        per_device_train_batch_size=1,\n        per_device_eval_batch_size=1,\n        remove_unused_columns=False,\n        eval_strategy=\"steps\",\n        eval_steps=10,\n        output_dir=\"output\",\n    ),\n    compute_metrics=define_compute_metrics(final_ds['test']),\n    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:00.999529Z","iopub.execute_input":"2024-10-08T16:54:00.999817Z","iopub.status.idle":"2024-10-08T16:54:04.319984Z","shell.execute_reply.started":"2024-10-08T16:54:00.999786Z","shell.execute_reply":"2024-10-08T16:54:04.319196Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"masked = trainer5.data_collator.torch_call([trainer5.train_dataset[0]])\nmasked = masked.to(model.device)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:04.321147Z","iopub.execute_input":"2024-10-08T16:54:04.321477Z","iopub.status.idle":"2024-10-08T16:54:04.340358Z","shell.execute_reply.started":"2024-10-08T16:54:04.321443Z","shell.execute_reply":"2024-10-08T16:54:04.339477Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"masked","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:04.341542Z","iopub.execute_input":"2024-10-08T16:54:04.341818Z","iopub.status.idle":"2024-10-08T16:54:04.390334Z","shell.execute_reply.started":"2024-10-08T16:54:04.341786Z","shell.execute_reply":"2024-10-08T16:54:04.389426Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'prompt_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'completion_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'input_ids': tensor([[    2, 48134, 15680,    35,  1336,    64,    52,  5368,    10,    92,\n         23669,  1842,    19,    10,   576,  1270,  6694,    11, 18434,   116,\n         50118, 48134, 41327,    35,  1270,  5457,    22,  2387,  7086,   113,\n         50118, 48134, 31652,    35, 20836,  1270,  5457,    22,  2387,  7086,\n           113, 50118, 20836,    92, 21823,  5457, 22209, 41552,  6660, 49007,\n          3628, 49007, 14691, 15698, 49316, 14691, 24303, 49138, 14691, 49007,\n          3628, 49526,  6660, 15698, 12905,   131,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1]], device='cuda:0'), 'labels': tensor([[    2, 48134, 15680,    35,  1336,    64,    52,  5368,    10,    92,\n         23669,  1842,    19,    10,   576,  1270,  6694,    11, 18434,   116,\n         50118, 48134, 41327,    35,  1270,  5457,    22,  2387,  7086,   113,\n         50118, 48134, 31652,    35, 20836,  1270,  5457,    22,  2387,  7086,\n           113, 50118, 20836,    92, 21823,  5457, 22209, 41552,  6660, 49007,\n          3628, 49007, 14691, 15698, 49316, 14691, 24303, 49138, 14691, 49007,\n          3628, 49526,  6660, 15698, 12905,   131,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"},"metadata":{}}]},{"cell_type":"code","source":"loss, outputs = trainer5.compute_loss(model, masked, return_outputs=True)\nloss","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:04.391297Z","iopub.execute_input":"2024-10-08T16:54:04.391556Z","iopub.status.idle":"2024-10-08T16:54:05.028690Z","shell.execute_reply.started":"2024-10-08T16:54:04.391527Z","shell.execute_reply":"2024-10-08T16:54:05.027479Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"tensor(3.0782, device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"trainer5.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T16:54:05.029769Z","iopub.execute_input":"2024-10-08T16:54:05.030081Z","iopub.status.idle":"2024-10-08T16:59:56.423821Z","shell.execute_reply.started":"2024-10-08T16:54:05.030048Z","shell.execute_reply":"2024-10-08T16:59:56.422344Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241008_165452-lzrhb3ww</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aymantarig17-ml/huggingface/runs/lzrhb3ww' target=\"_blank\">output</a></strong> to <a href='https://wandb.ai/aymantarig17-ml/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aymantarig17-ml/huggingface' target=\"_blank\">https://wandb.ai/aymantarig17-ml/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aymantarig17-ml/huggingface/runs/lzrhb3ww' target=\"_blank\">https://wandb.ai/aymantarig17-ml/huggingface/runs/lzrhb3ww</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21' max='53529' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   21/53529 04:49 < 226:49:57, 0.07 it/s, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Comp Loss</th>\n      <th>Prompt Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>2.531247</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>284.848700</td>\n      <td>6.962000</td>\n      <td>6.962000</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='55' max='1983' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  55/1983 00:07 < 04:36, 6.96 it/s]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: BatchEncoding.to() got an unexpected keyword argument 'non_blocking'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:434\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 434\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2467\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2915\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2913\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2872\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2872\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3868\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3865\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3867\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3868\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3869\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:4051\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4048\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4050\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 4051\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   4052\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   4053\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   4054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:559\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    561\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# `torch.Tensor.to(<int num>)` is not supported by `torch_npu` (see this [issue](https://github.com/Ascend/pytorch/issues/16)).\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# This call is inside the try-block since is_npu_available is not supported by torch.compile.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:816\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    818\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:816\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    818\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}